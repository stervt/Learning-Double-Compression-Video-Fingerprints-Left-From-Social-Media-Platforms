{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from requests import patch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random \n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_frames_by_patches(video_path,frame_list,num):\n",
    "    \"\"\" Randomly select frames according to the number of image patches that a video needs\n",
    "\n",
    "    Args:\n",
    "        video_path ( str ): the path of video frame\n",
    "        frame_list ( str ): the list of video frame\n",
    "        num ( int ): the number of patches that a video needs\n",
    "    \"\"\"\n",
    "    \n",
    "    img  = Image.open(os.path.join(video_path,frame_list[0]))\n",
    "    n = (img.size[0]//256)*(img.size[1]//256)\n",
    "    n_frames = int(num/n)\n",
    "    if len(frame_list) < n_frames:\n",
    "        return frame_list\n",
    "    return random.sample(frame_list,n_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image(img):\n",
    "    \n",
    "    \"\"\" Spilit the PIL Image to patches\"\"\"\n",
    "\n",
    "    cropped = []\n",
    "    size = img.size\n",
    "    w = size[0]//256\n",
    "    h =  size[1]//256\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            box = (256 * i, 256 * j, 256 * (i + 1), 256 * (j + 1))\n",
    "            region = img.crop(box)\n",
    "            cropped.append(np.array(region))\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_2_pickle(img,save_path):\n",
    "    \"\"\" convert image patches into pickles\n",
    "\n",
    "    Args:\n",
    "        img (_type_): image patch\n",
    "        path (_type_): the save path of patch\n",
    "    \"\"\"\n",
    "    with open(save_path,'wb') as f:\n",
    "        pickle.dump(img,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_consecutive_P_frames(i_frames_no, P_list):\n",
    "    \"\"\" find the consecutive frames after certain I frame\n",
    "\n",
    "    Args:\n",
    "        i_frames_no (int): idx of I frame\n",
    "        P_list (list): the list of P frames\n",
    "\n",
    "    Returns:\n",
    "        _type_: The first P frame after the I frame\n",
    "    \"\"\"\n",
    "    i_frames_no =int(i_frames_no.split('.')[0]) \n",
    "    for i in range(len(P_list)):\n",
    "        if P_list[i] > i_frames_no:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_patch(img_name,ftype):\n",
    "    l = img_name.split('.jpg')[0].split('/')\n",
    "    return '{}_{}_{}_{}'.format(l[0],l[1],ftype,l[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(frame_dir,save_text_path,num_of_P_frames=3,num_of_patches=140):\n",
    "    \"\"\" create I frame and P frame patches and out the pair info to specific text file\n",
    "\n",
    "    Args:\n",
    "        frame_dir (str): the path of frames dir\n",
    "        save_text_path (str): the save path of output text file\n",
    "        num_of_P_frames (int, optional): the number of consecutive P frames. Defaults to 3.\n",
    "        num_of_patches (int, optional): the number of patches a video needs. Defaults to 140.\n",
    "    \"\"\"\n",
    "    # 首先获取所有视频列表\n",
    "    video_list = os.listdir(frame_dir)\n",
    "    # 再对每个视频单独处理\n",
    "    # 首先选取视频的I帧\n",
    "    with open(os.path.join(save_text_path),\"a+\") as f:\n",
    "        for video in video_list:\n",
    "            I_frame_path = os.path.join(frame_dir,video,'I')\n",
    "            # 读取I帧的列表\n",
    "            I_frame_list = os.listdir(I_frame_path)\n",
    "            # 根据需要切出的图像块的个数来选择I帧\n",
    "            selected_I_frames = select_frames_by_patches(I_frame_path,I_frame_list,num_of_patches)\n",
    "            # 根据Iframe来选择Pframes\n",
    "            # 首先获取P帧列表\n",
    "            P_frame_path = os.path.join(frame_dir,video,'P')\n",
    "            P_frame_list = os.listdir(P_frame_path)\\\n",
    "            # 对每个I帧，选择其随后的n个P帧\n",
    "            for i in range(len(P_frame_list)):\n",
    "                P_frame_list[i] = int(P_frame_list[i].split('.jpg')[0])\n",
    "            P_frame_list.sort()\n",
    "            len_p_frames = len(P_frame_list)\n",
    "            for f_no in selected_I_frames:\n",
    "                p_idx = find_consecutive_P_frames(f_no,P_frame_list) \n",
    "                if p_idx ==None:\n",
    "                    print(os.path.join(video,'I',str(f_no)+'.jpg'))\n",
    "                # 如果I帧后存在n个P帧，则将其写入txt中\n",
    "                else:\n",
    "                    if (p_idx+num_of_P_frames) < len_p_frames:\n",
    "                        f.writelines(os.path.join(video,'I',str(f_no))+'\\n')\n",
    "                        for i in range(num_of_P_frames):\n",
    "                            f.writelines(os.path.join(video,'P',str(P_frame_list[p_idx+i]))+'.jpg\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(txt_path,frame_dir,label,save_dir):\n",
    "    \"\"\" crete dataset\n",
    "\n",
    "    Args:\n",
    "        txt_path (_type_): the path of text file that contains pairs info about I frames and P frames\n",
    "        frame_dir (_type_): the path of frames dir\n",
    "        label (_type_): the label of frames\n",
    "        save_dir (_type_): the save path of created dataset\n",
    "    \"\"\"\n",
    "    # 首先读取保存I帧P帧对的文本\n",
    "    frame_list = [] \n",
    "    pair = []\n",
    "    with open(txt_path,\"r\") as f: \n",
    "        count = 1\n",
    "        for item in f.readlines():\n",
    "            pair.append(item.strip())\n",
    "            if count==3:\n",
    "                frame_list.append(pair)\n",
    "                pair = []\n",
    "                count = 1\n",
    "            else:\n",
    "                count+=1\n",
    "    # 接下来对进行切片处理\n",
    "    video_name = ''\n",
    "    for frames in tqdm(frame_list):\n",
    "        if frames[0].split('/')[0] != video_name:\n",
    "            video_name = frames[0].split('/')[0]\n",
    "            n = 0\n",
    "        I_patch = split_image(Image.open(os.path.join(frame_dir,frames[0])))\n",
    "        P_patch = []\n",
    "        for i in range(1,4):    \n",
    "            P_patch.append(split_image(Image.open(os.path.join(frame_dir,frames[0]))))\n",
    "        I_name = rename_patch(frames[0],label)\n",
    "        P_name_1 = rename_patch(frames[1],label)\n",
    "        P_name_2 = rename_patch(frames[2],label)\n",
    "        P_name_3 = rename_patch(frames[3],label)\n",
    "        for j in range(len(I_patch)):\n",
    "            name_1 = '{}_{}.pickle'.format(I_name,j)\n",
    "            name_2 = '{}_{}.pickle'.format(P_name_1,j)\n",
    "            name_3 = '{}_{}.pickle'.format(P_name_2,j)\n",
    "            name_4 = '{}_{}.pickle'.format(P_name_3,j)\n",
    "            convert_img_2_pickle(I_patch[j],os.path.join(save_dir,name_1))\n",
    "            convert_img_2_pickle(P_patch[0][j],os.path.join(save_dir,name_2))\n",
    "            convert_img_2_pickle(P_patch[1][j],os.path.join(save_dir,name_3))\n",
    "            convert_img_2_pickle(P_patch[2][j],os.path.join(save_dir,name_4))\n",
    "            with open(os.path.join(save_dir,'FB_test.txt'),'a') as f:\n",
    "                f.writelines('{} {} {} {} {} {}\\n'.format(name_1,name_2,name_3,name_4,label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pairs(\"./data/frames/FB/\",\"FB.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 716/716 [01:05<00:00, 10.94it/s]\n"
     ]
    }
   ],
   "source": [
    "create_dataset('FB.txt','./data/frames/FB','FB','/data/frames/patches/train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('new_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83c72a0a2c5ea90ed41ffed2931860438f0edeed20db8de5fc94f67f0e2aa458"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
